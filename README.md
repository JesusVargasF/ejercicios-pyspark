# Repositorio de Ejercicios de Apache Spark - Data Engineer Academy (Xideral)

![Apache Spark Logo](https://spark.apache.org/images/spark-logo-trademark.png)

Este repositorio contiene los ejercicios realizados durante la **Academia de Data Engineer** de **Xideral**, donde se exploraron diversas técnicas y herramientas para el procesamiento distribuido de datos utilizando **Apache Spark**. Los ejercicios abarcan desde la carga y transformación de datos hasta consultas utilizando **PySpark** y **Spark SQL**.

El proyecto incluye ejercicios con datos provenientes de diferentes fuentes, como **Kaggle**, **Project Gutenberg**, y otros datasets públicos. Además, se utilizó **AWS EC2** para ejecutar los trabajos de Spark en un entorno distribuido y **Jupyter Notebook** para documentar y visualizar los análisis.

---

## Descripción del repositorio

Este repositorio es una compilación de ejercicios prácticos realizados durante la acdemia de **Data Engineering** en **Xideral**. El objetivo principal fue aprender a utilizar **Apache Spark** para procesar grandes volúmenes de datos de manera eficiente y escalable.

Los ejercicios cubren una variedad de temas, como:

- Carga y procesamiento de datos desde diferentes fuentes.
- Transformaciones y acciones en RDDs y DataFrames.
- Consultas avanzadas utilizando **PySpark SQL**.
- Análisis de texto utilizando datos de **Project Gutenberg** y **Kaggle**.

---

## Tecnologías Utilizadas

- **Apache Spark**: Framework de procesamiento distribuido utilizado para realizar las transformaciones y análisis de datos.
- **PySpark**: API de Python para interactuar con Spark.
- **AWS EC2**: Servicio de computación en la nube utilizado para ejecutar trabajos de Spark en un contenedor de **DOCKER**.
- **Jupyter Notebook**: Entorno interactivo utilizado para desarrollar y documentar los ejercicios.
- **Datasets**: Datos provenientes de fuentes como **Kaggle**, **Project Gutenberg**.

---
